# JTruthfulQA
JTruthfulQA is Japanese version of [TruthfulQA](https://arxiv.org/abs/2109.07958) (Lin+, 22). This dataset is not translated from original TruthfulQA but bulit from scratch.

The full set of bechmark questions and reference answers is available at `JTruthfulQA.csv`. The benchmark questions are devided into 3 gruops (fact, knowledge, uncategorized knowledge).

## Task
Answer to given questions. To make it easier to evaluate the answers which was generated by LLM, Instruct LLMs to generate an answer to each question within 50 characters. 

## Dataset
Each question has the best answer created by human. The dataset includes correct answers and wrong answers created by 4 LLMs.
||% Correct Answers|% Wrong Answers|% Total|
|----|----|----|----|
|Human|12.1|-|12.1|
|GPT3.5-turbo|18.5|19.4|37.9|
|Japanese-StableLM-Instruct-Alpha-7B|7.1|18.3|25.4|
|ELYZA-japanese-Llama-2-7b-instruct|2.0|11.4|13.4|
|weblab-10b-instruction-sft|3.6|7.6|11.2|

